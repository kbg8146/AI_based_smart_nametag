{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3ctM2HTHqwj"
      },
      "outputs": [],
      "source": [
        "# âœ… 1. ì„¤ì¹˜ ë° ì¸ì¦\n",
        "!pip install --upgrade openai==0.28 gspread gspread_dataframe oauth2client umap-learn\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gspread\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as mcolors\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from google.auth import default\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.metrics import silhouette_score\n",
        "from matplotlib.patches import Patch\n",
        "from collections import defaultdict\n",
        "import openai\n",
        "import re\n",
        "\n",
        "# âœ… 2. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1kkt336f1G-XqfDuwCUOnqpKlxTcnwLQy-XS4SQv6lM0/edit\"\n",
        "sh = gc.open_by_url(spreadsheet_url)\n",
        "\n",
        "survey_ws = sh.worksheet(\"ì„¤ë¬¸ì§€ ì‘ë‹µ ì‹œíŠ¸\")\n",
        "score_ws  = sh.worksheet(\"ê³¼ëª©ë³„ ì§ë¬´ ê°€ì¤‘ì¹˜1\")\n",
        "\n",
        "# âœ… 3. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "survey_df = pd.DataFrame(survey_ws.get_all_records())\n",
        "score_df  = pd.DataFrame(score_ws.get_all_records()).set_index(\"ê³¼ëª©ëª…\")\n",
        "industries = list(score_df.columns)\n",
        "\n",
        "# âœ… 4. GPT API í‚¤ ì„¤ì •\n",
        "openai.api_key = \"\"\n",
        "\n",
        "# âœ… 5. GPT ì ìˆ˜ ìƒì„± í•¨ìˆ˜\n",
        "def gpt_industry_score(text):\n",
        "    prompt = f\"\"\"\n",
        "ë‹¤ìŒì€ ê³µëŒ€ìƒì˜ í”„ë¡œì íŠ¸ ë˜ëŠ” í™œë™ ì„¤ëª…ì…ë‹ˆë‹¤.\n",
        "ì•„ë˜ ì‚°ì—…êµ° ëª©ë¡ ì¤‘ ê´€ë ¨ëœ í•­ëª©ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ 1~3ì (ì •ìˆ˜)ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì„¸ìš”.\n",
        "- ë°˜ë“œì‹œ ì•„ë˜ í•­ëª©ëª…ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n",
        "- ì¤‘ìš”ë„ê°€ ë‚®ì•„ë„ 1ì  ì´ìƒ ë¶€ì—¬í•˜ì„¸ìš”.\n",
        "\n",
        "[ì‚°ì—…êµ° ëª©ë¡]\n",
        "{', '.join(industries)}\n",
        "\n",
        "ì„¤ëª…:\n",
        "{text}\n",
        "\n",
        "ì˜ˆì‹œ:\n",
        "{industries[0]}: 2, {industries[1]}: 1, {industries[2]}: 3\n",
        "\"\"\"\n",
        "    try:\n",
        "        resp = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0\n",
        "        )\n",
        "        content = resp.choices[0].message.content\n",
        "        print(\"ğŸ¤– GPT ì‘ë‹µ:\\n\", content)\n",
        "\n",
        "        scores = pd.Series(0, index=industries, dtype=float)\n",
        "        parts = re.split(r\"[,\\n]\", content)\n",
        "        for part in parts:\n",
        "            match = re.search(r\"(.+?):\\s*([\\d.]+)\", part)\n",
        "            if match:\n",
        "                k = match.group(1).strip()\n",
        "                v = float(match.group(2))\n",
        "                if k in scores:\n",
        "                    scores[k] = min(max(v, 1.0), 3.0)\n",
        "        return scores\n",
        "    except Exception as e:\n",
        "        print(\"GPT ì˜¤ë¥˜:\", e)\n",
        "        return pd.Series(0, index=industries, dtype=float)\n",
        "\n",
        "# âœ… 6. ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜\n",
        "def calculate_combined_scores(row):\n",
        "    s = pd.Series(0, index=industries, dtype=float)\n",
        "    subj_score = pd.Series(0, index=industries, dtype=float)\n",
        "    gpt_score = pd.Series(0, index=industries, dtype=float)\n",
        "\n",
        "    subjects = [x.strip() for x in row[\"ìˆ˜ê°• í•œ ì „ê³µ ê³¼ëª© (ë³µìˆ˜ ì‘ë‹µ ê°€ëŠ¥)\"].split(',')]\n",
        "    for subj in subjects:\n",
        "        if subj in score_df.index:\n",
        "            subj_score += score_df.loc[subj]\n",
        "    s += subj_score\n",
        "\n",
        "    text = row.get(\"ê¸°íƒ€í™œë™/í”„ë¡œì íŠ¸ ê²½í—˜(ì£¼ê´€ì‹)\")\n",
        "    if pd.notna(text) and len(text.strip()) > 5:\n",
        "        gpt_score = gpt_industry_score(text)\n",
        "        s += gpt_score\n",
        "\n",
        "    if s.sum() > 0:\n",
        "        s = s / s.sum() * 100\n",
        "\n",
        "    return pd.concat([\n",
        "        pd.Series({\n",
        "            \"ê°ê´€ì‹ ì ìˆ˜ í•©ê³„\": subj_score.sum(),\n",
        "            \"ì£¼ê´€ì‹ ì ìˆ˜ í•©ê³„\": gpt_score.sum()\n",
        "        }),\n",
        "        subj_score.add_prefix(\"ê°ê´€ì‹_\"),\n",
        "        gpt_score.add_prefix(\"ì£¼ê´€ì‹_\"),\n",
        "        s\n",
        "    ])\n",
        "\n",
        "# âœ… 7. ì‚°ì—…êµ° ì ìˆ˜ ê³„ì‚°\n",
        "ind_scores = survey_df.apply(calculate_combined_scores, axis=1)\n",
        "df_scores = pd.concat([survey_df[[\"ì´ë©”ì¼ ì£¼ì†Œ\", \"ì´ë¦„\"]], ind_scores], axis=1)\n",
        "\n",
        "# âœ… 8. í´ëŸ¬ìŠ¤í„°ë§\n",
        "X = df_scores[industries].fillna(0).values\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "best_k, best_score = 0, -1\n",
        "for k in range(2, 7):\n",
        "    km = KMeans(n_clusters=k, random_state=42)\n",
        "    labels = km.fit_predict(X_scaled)\n",
        "    score = silhouette_score(X_scaled, labels)\n",
        "    if score > best_score:\n",
        "        best_k, best_score, best_kmeans, best_labels = k, score, km, labels\n",
        "\n",
        "kmeans = best_kmeans\n",
        "clusters = best_labels\n",
        "df_scores[\"Cluster\"] = clusters\n",
        "df_scores[\"Distance_to_Center\"] = kmeans.transform(X_scaled)[np.arange(len(X)), clusters]\n",
        "\n",
        "# âœ… 9. í´ëŸ¬ìŠ¤í„° ì´ë¦„ ìƒì„± ë° ì—°ê²°\n",
        "def get_cluster_names(centers, top_n=2):\n",
        "    names = []\n",
        "    for i in range(len(centers)):\n",
        "        top = centers.iloc[i].sort_values(ascending=False).head(top_n).index\n",
        "        names.append(\" + \".join(top))\n",
        "    return names\n",
        "\n",
        "centers = pd.DataFrame(kmeans.cluster_centers_, columns=industries)\n",
        "cluster_names = get_cluster_names(centers)\n",
        "df_scores[\"Top Industries\"] = df_scores[\"Cluster\"].map(lambda c: cluster_names[c])\n",
        "\n",
        "# âœ… 10. ì´ìƒì¹˜ íƒì§€\n",
        "m_dist = df_scores[\"Distance_to_Center\"].mean()\n",
        "s_dist = df_scores[\"Distance_to_Center\"].std()\n",
        "outlier_thresh = m_dist + 2 * s_dist\n",
        "df_scores[\"Outlier\"] = df_scores[\"Distance_to_Center\"] > outlier_thresh\n",
        "\n",
        "# âœ… 11. MDS ì‹œê°í™” (1ì°¨ êµ°ì§‘)\n",
        "X_aug = np.vstack([X_scaled, kmeans.cluster_centers_])\n",
        "mds = MDS(n_components=2, random_state=42)\n",
        "X_mds_all = mds.fit_transform(X_aug)\n",
        "X_mds = X_mds_all[:-best_k]\n",
        "centroids_2d = X_mds_all[-best_k:]\n",
        "\n",
        "df_scores[\"MDS1\"] = X_mds[:, 0]\n",
        "df_scores[\"MDS2\"] = X_mds[:, 1]\n",
        "\n",
        "# ìƒ‰ìƒ ë§¤í•‘\n",
        "def get_cluster_colors(n_clusters):\n",
        "    colormap = cm.get_cmap('tab20', n_clusters)\n",
        "    return [mcolors.rgb2hex(colormap(i)) for i in range(n_clusters)]\n",
        "colors = get_cluster_colors(best_k)\n",
        "\n",
        "# ì‹œê°í™” - 1ì°¨ í´ëŸ¬ìŠ¤í„°\n",
        "plt.figure(figsize=(10, 7))\n",
        "for i in range(best_k):\n",
        "    mask = df_scores[\"Cluster\"] == i\n",
        "    plt.scatter(df_scores.loc[mask, \"MDS1\"], df_scores.loc[mask, \"MDS2\"],\n",
        "                label=cluster_names[i], color=colors[i], s=70)\n",
        "plt.scatter(centroids_2d[:, 0], centroids_2d[:, 1], marker='X', c='black', s=200, label=\"Centers\")\n",
        "plt.title(\"MDS 2D Clustering Result (Primary Clustering)\")\n",
        "plt.legend(fontsize='small')\n",
        "plt.grid(True)\n",
        "plt.xlabel(\"MDS 1\")\n",
        "plt.ylabel(\"MDS 2\")\n",
        "plt.show()\n",
        "\n",
        "# âœ… 12. Subgroup êµ°ì§‘í™” (6~10ëª… ê¸°ì¤€)\n",
        "df_scores[\"Subgroup\"] = \"\"\n",
        "for c in range(best_k):\n",
        "    members = df_scores[df_scores[\"Cluster\"] == c]\n",
        "    n = len(members)\n",
        "\n",
        "    if n > 10:\n",
        "        n_sub = int(np.round(n / 8))\n",
        "        n_sub = max(1, min(n_sub, n // 6))\n",
        "        sub_X = members[[\"MDS1\", \"MDS2\"]].values\n",
        "        sub_kmeans = KMeans(n_clusters=n_sub, random_state=42).fit(sub_X)\n",
        "        for i, idx in enumerate(members.index):\n",
        "            df_scores.at[idx, \"Subgroup\"] = f\"{cluster_names[c]} Subgroup {sub_kmeans.labels_[i]+1}\"\n",
        "    else:\n",
        "        for idx in members.index:\n",
        "            df_scores.at[idx, \"Subgroup\"] = f\"{cluster_names[c]} Subgroup 1\"\n",
        "\n",
        "# âœ… 13. Subgroup ì‹œê°í™”\n",
        "subgroups = df_scores[\"Subgroup\"].unique()\n",
        "sub_color_map = {sg: cm.tab20(i / len(subgroups)) for i, sg in enumerate(subgroups)}\n",
        "df_scores[\"Sub_Color\"] = df_scores[\"Subgroup\"].map(sub_color_map)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(df_scores[\"MDS1\"], df_scores[\"MDS2\"], c=df_scores[\"Sub_Color\"], s=70, edgecolors='k')\n",
        "handles = [Patch(color=sub_color_map[sg], label=sg) for sg in sorted(subgroups)]\n",
        "plt.legend(handles=handles, title=\"Subgroups\", loc='best', fontsize='small')\n",
        "plt.title(\"MDS 2D Subgroup Clustering\")\n",
        "plt.xlabel(\"MDS 1\")\n",
        "plt.ylabel(\"MDS 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# âœ… 14. Google Sheet ì—…ë¡œë“œ\n",
        "try:\n",
        "    ws_old = sh.worksheet(\"Clustered Result with Distance\")\n",
        "    sh.del_worksheet(ws_old)\n",
        "except:\n",
        "    pass\n",
        "result_ws = sh.add_worksheet(title=\"Clustered Result with Distance\", rows=len(df_scores)+1, cols=80)\n",
        "set_with_dataframe(result_ws, df_scores)\n",
        "\n",
        "print(f\"âœ… ì™„ë£Œ: k={best_k}ë¡œ í´ëŸ¬ìŠ¤í„°ë§ + Subgroup ì™„ë£Œ ë° ì‹œíŠ¸ ì—…ë¡œë“œ\")"
      ]
    }
  ]
}